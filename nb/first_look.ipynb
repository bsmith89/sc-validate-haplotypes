{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.pandas_util import idxwhere\n",
    "from lib.project_style import color_palette, major_allele_frequency_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('data/all_drplt.a.proc.gtpro.2.denorm.db')\n",
    "\n",
    "con.executescript(\"\"\"\n",
    "    CREATE TEMP TABLE species AS\n",
    "    SELECT species_id, COUNT(species_position) AS position_total\n",
    "    FROM snp\n",
    "    GROUP BY species_id\n",
    "    ;\n",
    "\n",
    "    CREATE TEMP VIEW lib_x_species_tally AS\n",
    "    SELECT\n",
    "      lib_id\n",
    "    , species_id\n",
    "    , COUNT(species_position) AS position_tally\n",
    "    , SUM(reference_tally + alternative_tally) AS depth_tally\n",
    "    FROM snp_x_lib\n",
    "    GROUP BY lib_id, species_id\n",
    "    ;\n",
    "    \n",
    "    CREATE TEMP VIEW drplt_combined AS\n",
    "    SELECT\n",
    "      sample_id\n",
    "    , species_id\n",
    "    , species_position\n",
    "    , COUNT(lib_id) AS lib_tally\n",
    "    , SUM(reference_tally) AS reference_tally\n",
    "    , SUM(alternative_tally) AS alternative_tally\n",
    "    , SUM(reference_tally + alternative_tally) AS depth_tally\n",
    "    FROM snp_x_lib\n",
    "    JOIN lib USING (lib_id)\n",
    "    WHERE lib_type = 'droplet'\n",
    "    GROUP BY sample_id, species_id, species_position\n",
    "    ;\n",
    "    \n",
    "    CREATE TEMP VIEW mgen_combined AS\n",
    "    SELECT\n",
    "      sample_id\n",
    "    , species_id\n",
    "    , species_position\n",
    "    , COUNT(lib_id) AS lib_tally\n",
    "    , SUM(reference_tally) AS reference_tally\n",
    "    , SUM(alternative_tally) AS alternative_tally\n",
    "    , SUM(reference_tally + alternative_tally) AS depth_tally\n",
    "    FROM snp_x_lib\n",
    "    JOIN lib USING (lib_id)\n",
    "    WHERE lib_type = 'metagenome'\n",
    "    GROUP BY sample_id, species_id, species_position\n",
    "    ;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drplt_cvrg = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  sample_id\n",
    ", species_id\n",
    ", (1.0 * SUM(lib_tally)) / position_total AS mean_incidence\n",
    ", (1.0 * COUNT(*)) / position_total AS horizontal_coverage\n",
    ", (1.0 * SUM(depth_tally)) / position_total AS mean_depth\n",
    "FROM drplt_combined\n",
    "JOIN species USING (species_id)\n",
    "GROUP BY sample_id, species_id\n",
    ";\n",
    "\"\"\", con=con, index_col=['sample_id', 'species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_cvrg = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  sample_id\n",
    ", species_id\n",
    ", (1.0 * SUM(lib_tally)) / position_total AS mean_incidence\n",
    ", (1.0 * COUNT(*)) / position_total AS horizontal_coverage\n",
    ", (1.0 * SUM(depth_tally)) / position_total AS mean_depth\n",
    "FROM mgen_combined\n",
    "JOIN species USING (species_id)\n",
    "GROUP BY sample_id, species_id\n",
    ";\n",
    "\"\"\", con=con, index_col=['sample_id', 'species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = pd.read_sql(\"SELECT * FROM species\", con=con, index_col=['species_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_cvrg = pd.read_sql(\"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    , (1.0 * position_tally) / position_total AS horizontal_coverage\n",
    "    , (1.0 * depth_tally) / position_total AS mean_depth\n",
    "    FROM lib_x_species_tally\n",
    "    JOIN species USING (species_id)\n",
    "    ;\n",
    "\"\"\", con=con, index_col=[\"lib_id\", \"species_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = pd.read_sql(\"SELECT * FROM lib;\", con=con, index_col=[\"lib_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = pd.read_table('ref/gtpro/species_taxonomy_ext.tsv', names=['_1', 'species_id', 'taxon_string']).assign(species_id=lambda x: x.species_id.astype(str)).set_index('species_id').taxon_string\n",
    "species = species.apply(lambda x: pd.Series(x.split(';'), index=['d__', 'p__', 'c__', 'o__', 'f__', 'g__', 's__']))\n",
    "species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_stats = (\n",
    "    lib_cvrg\n",
    "    .groupby('lib_id')\n",
    "    .apply(lambda x: pd.Series(dict(\n",
    "        total_tally=x.depth_tally.sum(),\n",
    "        num_species_gt0=(x.depth_tally > 0).sum(),\n",
    "        num_species_gt1=(x.depth_tally > 1).sum(),\n",
    "        num_species_gt5=(x.depth_tally > 5).sum(),\n",
    "        num_species_gt10=(x.depth_tally > 10).sum(),\n",
    "        max_species_tally=x.depth_tally.max(),\n",
    "        species_id=x.depth_tally.idxmax()[1],\n",
    "    )))\n",
    ")\n",
    "lib_stats['frac_dominant'] = lib_stats.max_species_tally / lib_stats.total_tally\n",
    "\n",
    "lib_stats = lib_stats.assign(\n",
    "    max_depth=lib_cvrg.groupby('lib_id').mean_depth.max(),\n",
    "    purity=lib_cvrg.groupby('lib_id').mean_depth.max() / lib_cvrg.groupby('lib_id').mean_depth.sum()\n",
    ")\n",
    "lib_stats['contamination'] = 1 - lib_stats.purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drplt_to_sample = pd.read_sql(\"SELECT lib_id, sample_id FROM lib WHERE lib_type = 'droplet'\", con=con, index_col='lib_id').squeeze()\n",
    "drplt_to_sample.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are most droplets dominated by one species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_stats.groupby(drplt_to_sample).total_tally.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_stats.groupby(drplt_to_sample).total_tally.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_stats.groupby(lib.lib_type).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    lib_stats\n",
    "    .join(lib, on='lib_id')\n",
    "    [lambda x: x.lib_type == 'droplet']\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(d.total_tally.pipe(np.log10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (\n",
    "    lib_stats\n",
    "    .join(lib, on='lib_id')\n",
    "    .assign(log10_total_tally=lambda x: x.total_tally.pipe(np.log10))\n",
    "    [lambda x: x.lib_type == 'droplet']\n",
    ")\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(d, hue='sample_id', size=3, aspect=2);\n",
    "g.map(\n",
    "    sns.kdeplot,\n",
    "    'log10_total_tally',\n",
    "    cut=0,\n",
    ")\n",
    "g.ax.axvline(np.log10(d.total_tally.median()), lw=1, linestyle='--', color='k', label='median')\n",
    "g.ax.axvline(np.log10(d.total_tally.mean()), lw=1, linestyle=':', color='k', label='mean')\n",
    "\n",
    "g.ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(\n",
    "    x='total_tally',\n",
    "    y='max_species_tally',\n",
    "    data=(\n",
    "        lib_stats\n",
    "        .join(lib, on='lib_id')\n",
    "        [lambda x: x.lib_type == 'droplet']\n",
    "    ),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=2, alpha=0.8)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.plot([1e-1, 4e6], [1e-1, 4e6], lw=1, linestyle='--', color='k', alpha=0.1)\n",
    "g.ax_joint.axvline(lib_stats.groupby(lib.lib_type).total_tally.median()['droplet'], lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.axvline(lib_stats.groupby(lib.lib_type).total_tally.mean()['droplet'], lw=1, linestyle=':', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(\n",
    "    x='max_depth',\n",
    "    y='contamination',\n",
    "    data=(\n",
    "        lib_stats\n",
    "        .join(lib, on='lib_id')\n",
    "        [lambda x: x.lib_type == 'droplet']\n",
    "    ),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('symlog', linthreshy=1e-3)\n",
    "g.ax_joint.set_ylim(-1e-4)\n",
    "g.ax_joint.set_xscale('log')\n",
    "# g.ax_joint.set_xscale('symlog', linthreshx=1e-2)\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3, alpha=0.8)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "# g.ax_joint.legend(loc='lower right')\n",
    "\n",
    "#g.ax_joint.plot([1, 1e8], [1, 1e8], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lib_stats.drop(['SS01009.m', 'SS01057.m'])[lambda x: x.max_depth > 1e-1].purity, bins=51)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('purity')\n",
    "# plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check genome coverage across species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth and horizontal coverage across libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='mean_depth',\n",
    "    y='horizontal_coverage',\n",
    "    data=(\n",
    "        lib_cvrg\n",
    "        .join(lib, on='lib_id')\n",
    "    ),\n",
    "    hue='lib_type',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just in metagenomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='mean_depth',\n",
    "    y='horizontal_coverage',\n",
    "    data=mgen_cvrg,\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just in droplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='mean_depth',\n",
    "    y='horizontal_coverage',\n",
    "    data=drplt_cvrg,\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do summed droplets resemble the full metagenomes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequencing depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='mean_depth_m',\n",
    "    y='mean_depth_d',\n",
    "    data=mgen_cvrg.join(drplt_cvrg, rsuffix='_d', lsuffix='_m').fillna(min_value),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horizontal coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='horizontal_coverage_m',\n",
    "    y='horizontal_coverage_d',\n",
    "    data=mgen_cvrg.join(drplt_cvrg, rsuffix='_d', lsuffix='_m').fillna(min_value),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_rabund = mgen_cvrg.groupby('sample_id', group_keys=False).apply(lambda x: x.mean_depth / x.mean_depth.sum()).rename('rabund')\n",
    "drplt_rabund = drplt_cvrg.groupby('sample_id', group_keys=False).apply(lambda x: x.mean_depth / x.mean_depth.sum()).rename('rabund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='rabund_m',\n",
    "    y='rabund_d',\n",
    "    data=mgen_rabund.to_frame().join(drplt_rabund, rsuffix='_d', lsuffix='_m').fillna(1e-9),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=3)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(\n",
    "    x='SS01009',\n",
    "    y='SS01057',\n",
    "    data=mgen_rabund.to_frame().join(drplt_rabund, lsuffix='_m', rsuffix='_d').fillna(1e-4).apply(lambda x: np.log(x.rabund_d / x.rabund_m), axis=1).unstack('sample_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do droplet frequencies resemble the full metagenomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dominated_libs = lib_stats.frac_dominant > 0.5\n",
    "\n",
    "frac_droplets = (\n",
    "    lib_cvrg\n",
    "    .loc[idxwhere(species_dominated_libs)]\n",
    "    .groupby('lib_id')\n",
    "    .mean_depth\n",
    "    .idxmax()\n",
    "    .rename('species_id')\n",
    "    .apply(lambda x: x[1])\n",
    "    .groupby(lib.sample_id)\n",
    "    .value_counts()\n",
    "    .groupby('sample_id')\n",
    "    .apply(lambda x: x / x.sum())\n",
    "    .rename('frac')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(\n",
    "    x='rabund',\n",
    "    y='frac',\n",
    "    data=mgen_rabund.to_frame().join(frac_droplets).fillna(1e-4),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "g.ax_joint.set_yscale('log')\n",
    "g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=10, alpha=0.5)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "# g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([1e-4, 1], [1e-4, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.JointGrid(\n",
    "    x='rabund',\n",
    "    y='frac',\n",
    "    data=mgen_rabund.to_frame().join(frac_droplets).fillna(1e-4),\n",
    "    hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "# g.ax_joint.set_yscale('log')\n",
    "# g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.scatterplot, s=10, alpha=0.5)\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "# g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([1e-4, 1.0], [1e-4, 1.0], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import construct_ordered_pallete\n",
    "\n",
    "pal = construct_ordered_pallete(species.sort_values(['d__', 'p__', 'c__']).c__)\n",
    "\n",
    "d = mgen_rabund.to_frame().join(frac_droplets).fillna(1e-8).join(species).sort_values(['d__', 'p__', 'c__'])\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(d, hue='c__', size=5, palette=pal);\n",
    "g.map(\n",
    "    sns.scatterplot,\n",
    "    'rabund',\n",
    "    'frac',\n",
    ")\n",
    "\n",
    "g.ax.set_yscale('log')\n",
    "g.ax.set_xscale('log')\n",
    "g.ax.plot([1e-8, 1], [1e-8, 1], lw=1, linestyle='--', color='k')\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import construct_ordered_pallete\n",
    "\n",
    "pal = construct_ordered_pallete(species.sort_values(['d__', 'p__', 'c__']).c__)\n",
    "\n",
    "d = (\n",
    "    mgen_rabund\n",
    "    .to_frame()\n",
    "    .join(frac_droplets)\n",
    "    .fillna(1e-4)\n",
    "    .apply(lambda x: np.log(x.frac / x.rabund), axis=1)\n",
    "    .unstack('sample_id')\n",
    "    .join(species)\n",
    "    .sort_values(['d__', 'p__', 'c__'])\n",
    ")\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(d, hue='c__', size=5, palette=pal);\n",
    "g.map(\n",
    "    sns.scatterplot,\n",
    "    'SS01009',\n",
    "    'SS01057',\n",
    ")\n",
    "# sns.regplot(\n",
    "#     x='SS01009',\n",
    "#     y='SS01057',\n",
    "#     data=d,\n",
    "#     scatter=False,\n",
    "#     color='k',\n",
    "#     line_kws=dict(alpha=0.5),\n",
    "# )\n",
    "plt.plot([-5, 10], [-5, 10], linestyle='--', lw=1, color='k')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import construct_ordered_pallete\n",
    "\n",
    "pal = construct_ordered_pallete(species.sort_values(['d__', 'p__', 'c__']).c__)\n",
    "\n",
    "d = (\n",
    "    mgen_rabund\n",
    "    .to_frame()\n",
    "    .join(frac_droplets, how='inner')\n",
    "    .fillna(1e-4)\n",
    "    .apply(lambda x: np.log(x.frac / x.rabund), axis=1)\n",
    "    .unstack('sample_id')\n",
    "    .join(species)\n",
    "    .sort_values(['d__', 'p__', 'c__'])\n",
    ")\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(d, hue='c__', size=5, palette=pal);\n",
    "g.map(\n",
    "    sns.scatterplot,\n",
    "    'SS01009',\n",
    "    'SS01057',\n",
    ")\n",
    "# sns.regplot(\n",
    "#     x='SS01009',\n",
    "#     y='SS01057',\n",
    "#     data=d,\n",
    "#     scatter=False,\n",
    "#     color='k',\n",
    "#     line_kws=dict(alpha=0.5),\n",
    "# )\n",
    "plt.plot([-5, 10], [-5, 10], linestyle='--', lw=1, color='k')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.plot import construct_ordered_pallete\n",
    "\n",
    "pal = construct_ordered_pallete(species.sort_values(['d__', 'p__', 'c__']).c__)\n",
    "\n",
    "d = (\n",
    "    mgen_rabund\n",
    "    .to_frame()\n",
    "    .join(frac_droplets, how='inner')\n",
    "    .fillna(1e-4)\n",
    "    .apply(lambda x: np.log(x.frac / x.rabund), axis=1)\n",
    "    .unstack('sample_id')\n",
    "    .join(species)\n",
    "    .sort_values(['d__', 'p__', 'c__'])\n",
    ")\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(d, hue='c__', size=5, palette=pal);\n",
    "g.map(\n",
    "    sns.scatterplot,\n",
    "    'SS01009',\n",
    "    'SS01057',\n",
    ")\n",
    "# sns.regplot(\n",
    "#     x='SS01009',\n",
    "#     y='SS01057',\n",
    "#     data=d,\n",
    "#     scatter=False,\n",
    "#     color='k',\n",
    "#     line_kws=dict(alpha=0.5),\n",
    "# )\n",
    "plt.plot([-5, 10], [-5, 10], linestyle='--', lw=1, color='k')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do droplets have much strain admixture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_genotype = pd.read_sql(\"\"\"\n",
    "WITH\n",
    "summed AS\n",
    "    (\n",
    "    SELECT *, reference_tally + alternative_tally AS total_tally\n",
    "    FROM snp_x_lib\n",
    "    ),\n",
    "drplt_normalized AS\n",
    "    (\n",
    "    SELECT\n",
    "        lib_id\n",
    "      , species_id\n",
    "      , species_position\n",
    "      , 1.0 * reference_tally / total_tally AS reference_tally\n",
    "      , 1.0 * alternative_tally / total_tally AS alternative_tally\n",
    "      , total_tally\n",
    "    FROM summed\n",
    "    )\n",
    "SELECT\n",
    "  lib_id\n",
    ", species_id\n",
    ", species_position\n",
    ", drplt_normalized.total_tally AS total_tally\n",
    ", drplt_normalized.reference_tally AS reference_tally\n",
    ", drplt_normalized.alternative_tally AS alternative_tally\n",
    ", MAX(drplt_normalized.reference_tally, drplt_normalized.alternative_tally) AS max_allele_frac\n",
    "FROM drplt_normalized\n",
    "JOIN lib USING (lib_id)\n",
    "\"\"\", con=con, index_col=['lib_id', 'species_id', 'species_position'])\n",
    "lib_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = lib_genotype[lambda x: x.total_tally > 15].max_allele_frac\n",
    "bins = np.linspace(0.5, 1.0)\n",
    "\n",
    "plt.hist(\n",
    "    d.loc[['SS01009.m', 'SS01057.m']],\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['metagenome'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='metagenome',\n",
    ")\n",
    "plt.hist(\n",
    "    d.loc[idxwhere(species_dominated_libs)],\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['droplet'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='droplet',\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are droplets representative of the associated metagenomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_drplt_genotype = pd.read_sql(\"\"\"\n",
    "SELECT\n",
    "  sample_id\n",
    ", species_id\n",
    ", species_position\n",
    ", SUM(reference_tally) AS reference_tally\n",
    ", SUM(alternative_tally) AS alternative_tally\n",
    "FROM snp_x_lib\n",
    "JOIN lib USING (lib_id)\n",
    "WHERE lib_type = 'droplet'\n",
    "GROUP BY sample_id, species_id, species_position\n",
    "\"\"\", con=con, index_col=['sample_id', 'species_id', 'species_position'])\n",
    "\n",
    "summed_drplt_genotype = (\n",
    "    summed_drplt_genotype\n",
    "    .assign(total_tally=lambda x: x.reference_tally + x.alternative_tally)\n",
    "    .assign(max_allele_frac=lambda x: x[['reference_tally', 'alternative_tally']].max(1) / x.total_tally)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgen_genotype = (\n",
    "    lib_genotype\n",
    "    .loc[['SS01009.m', 'SS01057.m']]\n",
    "    .rename({'SS01009.m': 'SS01009', 'SS01057.m': 'SS01057'})\n",
    "    .rename_axis(index={'lib_id': 'sample_id'})\n",
    "    .rename(columns={'reference_tally': 'reference_frac', 'alternative_tally': 'alternative_frac'})\n",
    ")\n",
    "# FIXME: Careful! Only works because there's just one library for each.\n",
    "# Instead you have to aggregate across libraries if you want it to be correct.\n",
    "\n",
    "# TODO: Build this similar to summed_drplt_genotype but for metagenomes\n",
    "\n",
    "# (\n",
    "#     lib_genotype\n",
    "#     .loc[['SS01009.m', 'SS01057.m']]\n",
    "#     .join(lib)\n",
    "#     .groupby(['sample_id', 'species_id', 'species_position'])\n",
    "#     .sum()\n",
    "#     [['total_tally', 'max_allele_frac']]\n",
    "# )\n",
    "\n",
    "mgen_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_mgen_genotype = pd.read_sql(\"\"\"\n",
    "WITH\n",
    "position_total AS\n",
    "(\n",
    "    SELECT *, reference_tally + alternative_tally AS total_tally\n",
    "    FROM snp_x_lib\n",
    "),\n",
    "\n",
    "drplt_genotype AS\n",
    "(\n",
    "    SELECT *\n",
    "  , 1.0 * reference_tally / total_tally AS reference_frac\n",
    "  , 1.0 * alternative_tally / total_tally AS alternative_frac\n",
    "    FROM position_total\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    sample_id\n",
    "  , species_id\n",
    "  , species_position\n",
    "  , AVG(reference_frac) AS reference_frac\n",
    "  , AVG(alternative_frac) AS alternative_frac\n",
    "  , COUNT(*) AS total_tally\n",
    "FROM drplt_genotype\n",
    "JOIN lib USING (lib_id)\n",
    "GROUP BY sample_id, species_id, species_position\n",
    ";\n",
    "\"\"\", con=con, index_col=['sample_id', 'species_id', 'species_position']).assign(\n",
    "        max_allele_frac=lambda x: x[['reference_frac', 'alternative_frac']].max(1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "virtual_mgen_genotype = (\n",
    "    lib_genotype\n",
    "    .join(lib)\n",
    "    .groupby(['sample_id', 'species_id', 'species_position'])\n",
    "    .apply(lambda x: pd.Series(dict(\n",
    "        total_tally=len(x.index),\n",
    "        reference_tally=x.reference_tally.sum(),\n",
    "        alternative_tally=x.alternative_tally.sum()\n",
    "    )))\n",
    "    .assign(\n",
    "        reference_frac=lambda x: x.reference_tally / x.total_tally,\n",
    "        alternative_frac=lambda x: x.alternative_tally / x.total_tally\n",
    "    )\n",
    "    .assign(\n",
    "        max_allele_frac=lambda x: x[['reference_frac', 'alternative_frac']].max(1)\n",
    "    )\n",
    ")\n",
    "virtual_mgen_genotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_mgen_genotype.groupby(['sample_id', 'species_id']).total_tally.mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    lib_stats\n",
    "    [lambda x: (x.frac_dominant > 0.5) & (x.max_species_tally > 100)]\n",
    "    .groupby(lib.sample_id)\n",
    "    .species_id\n",
    "    .value_counts()\n",
    "    .rename('tally')\n",
    "    .unstack('sample_id', fill_value=0)\n",
    "    .assign(total=lambda x: x.sum(1))\n",
    "    .join(species)\n",
    "    .sort_values('total', ascending=False)\n",
    "    .head(40)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_of_interest = 'SS01009'\n",
    "species_of_interest = '104345'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    (\n",
    "        lib_genotype\n",
    "        .loc[idxwhere(\n",
    "            (lib.lib_type == 'droplet') &\n",
    "            (lib.sample_id == sample_of_interest) &\n",
    "            lib.index.isin(lib_genotype.index.get_level_values('lib_id'))\n",
    "        )]\n",
    "        [lambda x: x.total_tally > 10]\n",
    "        .xs(species_of_interest, level='species_id')\n",
    "        .max_allele_frac\n",
    "    ),\n",
    "    bins=major_allele_frequency_bins,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=color_palette['droplet'],\n",
    "    label='droplet',\n",
    ")\n",
    "plt.hist(\n",
    "    (\n",
    "        mgen_genotype\n",
    "        .xs((sample_of_interest, species_of_interest), level=('sample_id', 'species_id'))\n",
    "        [lambda x: x.total_tally > 10]\n",
    "        .max_allele_frac\n",
    "    ),\n",
    "    bins=major_allele_frequency_bins,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=color_palette['metagenome'],\n",
    "    label='metagenome',\n",
    ")\n",
    "plt.hist(\n",
    "    (\n",
    "        virtual_mgen_genotype\n",
    "        .xs((sample_of_interest, species_of_interest), level=('sample_id', 'species_id'))\n",
    "        [lambda x: x.total_tally > 10]\n",
    "        .max_allele_frac\n",
    "    ),\n",
    "    bins=major_allele_frequency_bins,\n",
    "    density=True,\n",
    "    alpha=0.5,\n",
    "    color=color_palette['virtual-metagenome'],\n",
    "    label='virtual-metagenome',\n",
    ")\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "d = (\n",
    "    mgen_genotype.xs((sample_of_interest, species_of_interest), level=('sample_id', 'species_id'))\n",
    "    .join(virtual_mgen_genotype.xs((sample_of_interest, species_of_interest), level=('sample_id', 'species_id')), how='inner', lsuffix='_m', rsuffix='_d')\n",
    "    [lambda x: (x.total_tally_m > 100) & (x.max_allele_frac_m > 0.05) & (x.max_allele_frac_m < 0.95)]\n",
    ")\n",
    "\n",
    "g = sns.JointGrid(\n",
    "    x='reference_frac_m',\n",
    "    y='reference_frac_d',\n",
    "    data=d,\n",
    "#     hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "# g.ax_joint.set_yscale('log')\n",
    "# g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_joint(sns.regplot, line_kws={'color': 'k'})\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "# g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.5, 1.0)\n",
    "\n",
    "plt.hist(\n",
    "    mgen_genotype[lambda x: x.total_tally > 15].max_allele_frac,\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['metagenome'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='metagenome',\n",
    ")\n",
    "plt.hist(\n",
    "    virtual_mgen_genotype[lambda x: x.total_tally > 15].max_allele_frac,\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['virtual-metagenome'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='virtual-metagenome',\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0.5, 1.0)\n",
    "\n",
    "plt.hist(\n",
    "    mgen_genotype[lambda x: x.total_tally > 15].max_allele_frac,\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['metagenome'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='metagenome',\n",
    ")\n",
    "plt.hist(\n",
    "    virtual_mgen_genotype[lambda x: x.total_tally > 15].max_allele_frac,\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['virtual-metagenome'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='virtual-metagenome',\n",
    ")\n",
    "plt.hist(\n",
    "    (\n",
    "        lib_genotype\n",
    "        .loc[idxwhere(species_dominated_libs)]\n",
    "        [lambda x: x.total_tally > 15]\n",
    "        .max_allele_frac\n",
    "    ),\n",
    "    bins=major_allele_frequency_bins,\n",
    "    color=color_palette['droplet'],\n",
    "    alpha=0.5,\n",
    "    density=True,\n",
    "    label='droplet',\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-4)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = 1e-6\n",
    "\n",
    "d = (\n",
    "    mgen_genotype\n",
    "    .join(virtual_mgen_genotype, how='inner', lsuffix='_m', rsuffix='_d')\n",
    "    [lambda x: (x.total_tally_m > 100) & (x.max_allele_frac_m > 0.05) & (x.max_allele_frac_m < 0.95)]\n",
    ")\n",
    "\n",
    "g = sns.jointplot(\n",
    "    x='reference_frac_m',\n",
    "    y='reference_frac_d',\n",
    "    data=d,\n",
    "    kind='hex',\n",
    "#     hue='sample_id',\n",
    "    palette=color_palette,\n",
    ")\n",
    "# g.ax_joint.set_yscale('log')\n",
    "# g.ax_joint.set_xscale('log')\n",
    "\n",
    "g.plot_marginals(sns.kdeplot, common_norm=False)\n",
    "\n",
    "# g.ax_joint.axhline(0.1, lw=1, linestyle=':', color='k')\n",
    "g.ax_joint.plot([min_value, 1], [min_value, 1], lw=1, linestyle='--', color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}